{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install tensorflow-macos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Toxicity                                              tweet\n",
       "0           0         0   @user when a father is dysfunctional and is s...\n",
       "1           1         0  @user @user thanks for #lyft credit i can't us...\n",
       "2           2         0                                bihday your majesty\n",
       "3           3         0  #model   i love u take with u all the time in ...\n",
       "4           4         0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/FinalBalancedDataset.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant vectorisé les tweets, cela signifie donner une valeur numerique à chaques mot.\n",
    "Ces mots serons alors dans un dictionnaire dont on va décider de la capacité de celui (ici je vais prendre 150 000).\n",
    "On representera les tweets sous forme de tableau numpy. \n",
    "> Le dictionnaire que nous faisons est un vocabulaire compris uniquement par le model, on appel cela la tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(56745, 1300), dtype=int64, numpy=\n",
       "array([[    2,    34,     4, ...,     0,     0,     0],\n",
       "       [    2,     2,   233, ...,     0,     0,     0],\n",
       "       [  115,    27,  4880, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  389,  5936,   225, ...,     0,     0,     0],\n",
       "       [ 9865,    56,  1185, ...,     0,     0,     0],\n",
       "       [18062, 44065, 63266, ...,     0,     0,     0]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecteur = TextVectorization(max_tokens=150_000,output_sequence_length=1300,output_mode='int')\n",
    "# le vecteur apprend mtn notre vocabulaire \n",
    "vecteur.adapt(df['tweet'].values)\n",
    "# Il faut mtn vectorisé nos tweets\n",
    "text_vectorise = vecteur(df['tweet'].values) \n",
    "text_vectorise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation du dataset\n",
    "Maintenant que le vocabulaire existe et que les tweets sont vectoriser, il nous reste plus qu'a creer le dataset afin de l'envoyer au model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On cree le dataset avec les tweets vectorisés et les labels (on ajoute des options supplémentaire qui vont servire a l'entrainement)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((text_vectorise, df['Toxicity'].values)).cache().shuffle(60000).batch(10).prefetch(8)\n",
    "# Ici on va reperatir le contenu de notre dataset avec la partie entrainement 80%, evaluation 10% et test 10%\n",
    "octante = int(len(dataset)*.8)\n",
    "dix = int(len(dataset)*.1)\n",
    "train,val,test = (dataset.take(octante),dataset.skip(octante).take(dix),dataset.skip(octante+dix).take(dix))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "le dataset est maintenant configuré, il est temps de creer notre model, de l'entrainer et de l'evaluer.\n",
    "Dans le cadre du NLP et dans notre cas la compréhension de phrase de leur sens, il va falloir configurer le model de manière spécifique: \n",
    "- le nombre de couche egal au nombre max mot dans notre dictionnaire (embedding)\n",
    "- une bidirectionnalité très importatn pour le sens des phrases\n",
    "- Des couches intermédiaies qui connectent l'ensemble des couches   \n",
    "- Enfin la couche final avec la fonction sigmoid qui va nous renvoyer une valeur entre 0 et 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(150_001, 32))\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4540/4540 [==============================] - 1137s 250ms/step - loss: 0.1992 - val_loss: 0.0966\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy())\n",
    "res_train = model.fit(train, epochs=1, validation_data=val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
